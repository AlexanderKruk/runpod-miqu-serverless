runpod>=0.9.0
llama-cpp-python[server]>=0.2.23